{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvin/miniconda3/envs/linux-deep-gpu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mrigaankjaswal/exercise-detection-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.39M/1.39M [00:01<00:00, 1.04MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /home/kelvin/.cache/kagglehub/datasets/mrigaankjaswal/exercise-detection-dataset/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mrigaankjaswal/exercise-detection-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Side  Shoulder_Angle  Elbow_Angle   Hip_Angle  Knee_Angle  Ankle_Angle  \\\n",
      "0  left       10.639208   174.466813  174.785143  179.848140   179.419276   \n",
      "1  left       10.590342   174.428706  174.765042  179.775215   179.386147   \n",
      "2  left       10.546746   174.489431  174.785790  179.660017   179.333710   \n",
      "3  left       10.487682   174.614913  174.759542  179.614223   179.313926   \n",
      "4  left       10.412107   174.758503  174.737721  179.570564   179.298805   \n",
      "\n",
      "   Shoulder_Ground_Angle  Elbow_Ground_Angle  Hip_Ground_Angle  \\\n",
      "0                   90.0                90.0              90.0   \n",
      "1                   90.0                90.0              90.0   \n",
      "2                   90.0                90.0              90.0   \n",
      "3                   90.0                90.0              90.0   \n",
      "4                   90.0                90.0              90.0   \n",
      "\n",
      "   Knee_Ground_Angle  Ankle_Ground_Angle          Label  \n",
      "0               90.0                90.0  Jumping Jacks  \n",
      "1               90.0                90.0  Jumping Jacks  \n",
      "2               90.0                90.0  Jumping Jacks  \n",
      "3               90.0                90.0  Jumping Jacks  \n",
      "4               90.0                90.0  Jumping Jacks  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = os.path.join(path, 'exercise_angles.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Label'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31033, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 10:43:25.886552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741171406.112065   12572 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741171406.176000   12572 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 10:43:26.755691: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for column in df.columns:\n",
    "    features.append(column)\n",
    "\n",
    "targets = features.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hip_Angle',\n",
       " 'Knee_Angle',\n",
       " 'Ankle_Angle',\n",
       " 'Shoulder_Ground_Angle',\n",
       " 'Elbow_Ground_Angle',\n",
       " 'Hip_Ground_Angle',\n",
       " 'Knee_Ground_Angle',\n",
       " 'Ankle_Ground_Angle']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del features[0]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Label'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[targets] = label_encoder.fit_transform(df[targets])\n",
    "\n",
    "exercise_predictors = df[features].values\n",
    "exercise_categories = df[targets].values\n",
    "exercise_predictors_train, exercise_predictors_test, exercise_categories_train, exercise_categories_test = train_test_split(exercise_predictors, exercise_categories, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741171583.102779   12572 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741171588.274834   13822 service.cc:148] XLA service 0x7fd8d4002170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741171588.275550   13822 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-03-05 10:46:28.390894: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741171588.941186   13822 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "2025-03-05 10:46:32.915351: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_555', 68 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-03-05 10:46:33.700896: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_557', 68 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-03-05 10:46:33.887851: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_555', 68 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-03-05 10:46:33.890041: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_557', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 20/621\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3187 - loss: 3.3065 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741171597.975357   13822 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m614/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 1.0619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 10:46:46.719533: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_555', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-03-05 10:46:47.381938: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_557', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-03-05 10:46:47.880480: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_557', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-03-05 10:46:48.099817: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_555', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.6101 - loss: 1.0588 - val_accuracy: 0.7205 - val_loss: 0.6691\n",
      "Epoch 2/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7112 - loss: 0.6555 - val_accuracy: 0.7201 - val_loss: 0.6497\n",
      "Epoch 3/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.6246 - val_accuracy: 0.7332 - val_loss: 0.6085\n",
      "Epoch 4/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7253 - loss: 0.6044 - val_accuracy: 0.7338 - val_loss: 0.6515\n",
      "Epoch 5/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7338 - loss: 0.5909 - val_accuracy: 0.7038 - val_loss: 0.6367\n",
      "Epoch 6/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7344 - loss: 0.5880 - val_accuracy: 0.7441 - val_loss: 0.5744\n",
      "Epoch 7/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7466 - loss: 0.5699 - val_accuracy: 0.7414 - val_loss: 0.5643\n",
      "Epoch 8/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7474 - loss: 0.5566 - val_accuracy: 0.7720 - val_loss: 0.5390\n",
      "Epoch 9/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7564 - loss: 0.5447 - val_accuracy: 0.7648 - val_loss: 0.5340\n",
      "Epoch 10/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7608 - loss: 0.5386 - val_accuracy: 0.7813 - val_loss: 0.5099\n",
      "Epoch 11/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7644 - loss: 0.5278 - val_accuracy: 0.7841 - val_loss: 0.5366\n",
      "Epoch 12/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7624 - loss: 0.5239 - val_accuracy: 0.7831 - val_loss: 0.5238\n",
      "Epoch 13/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7646 - loss: 0.5169 - val_accuracy: 0.7441 - val_loss: 0.5516\n",
      "Epoch 14/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7670 - loss: 0.5122 - val_accuracy: 0.7590 - val_loss: 0.5597\n",
      "Epoch 15/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7681 - loss: 0.5118 - val_accuracy: 0.7676 - val_loss: 0.5358\n",
      "Epoch 16/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7779 - loss: 0.5070 - val_accuracy: 0.7612 - val_loss: 0.5781\n",
      "Epoch 17/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7837 - loss: 0.4867 - val_accuracy: 0.7783 - val_loss: 0.5216\n",
      "Epoch 18/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7791 - loss: 0.4960 - val_accuracy: 0.7813 - val_loss: 0.4923\n",
      "Epoch 19/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7786 - loss: 0.4883 - val_accuracy: 0.7874 - val_loss: 0.5121\n",
      "Epoch 20/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7793 - loss: 0.4851 - val_accuracy: 0.7465 - val_loss: 0.5424\n",
      "Epoch 21/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7784 - loss: 0.4849 - val_accuracy: 0.7811 - val_loss: 0.5166\n",
      "Epoch 22/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7877 - loss: 0.4731 - val_accuracy: 0.7890 - val_loss: 0.5514\n",
      "Epoch 23/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7714 - loss: 0.4962 - val_accuracy: 0.7900 - val_loss: 0.5500\n",
      "Epoch 24/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7820 - loss: 0.4858 - val_accuracy: 0.7821 - val_loss: 0.5049\n",
      "Epoch 25/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7792 - loss: 0.4790 - val_accuracy: 0.8196 - val_loss: 0.4664\n",
      "Epoch 26/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7947 - loss: 0.4649 - val_accuracy: 0.7565 - val_loss: 0.5513\n",
      "Epoch 27/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7979 - loss: 0.4661 - val_accuracy: 0.7497 - val_loss: 0.5656\n",
      "Epoch 28/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7836 - loss: 0.4716 - val_accuracy: 0.7918 - val_loss: 0.5279\n",
      "Epoch 29/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7917 - loss: 0.4603 - val_accuracy: 0.8077 - val_loss: 0.4708\n",
      "Epoch 30/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7965 - loss: 0.4588 - val_accuracy: 0.7900 - val_loss: 0.4977\n",
      "Epoch 31/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7867 - loss: 0.4677 - val_accuracy: 0.7626 - val_loss: 0.5820\n",
      "Epoch 32/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7927 - loss: 0.4663 - val_accuracy: 0.8002 - val_loss: 0.4924\n",
      "Epoch 33/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7949 - loss: 0.4553 - val_accuracy: 0.7755 - val_loss: 0.5238\n",
      "Epoch 34/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7949 - loss: 0.4545 - val_accuracy: 0.7892 - val_loss: 0.5017\n",
      "Epoch 35/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.8005 - loss: 0.4505 - val_accuracy: 0.7938 - val_loss: 0.5260\n",
      "Epoch 36/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8010 - loss: 0.4512 - val_accuracy: 0.7682 - val_loss: 0.5883\n",
      "Epoch 37/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7991 - loss: 0.4547 - val_accuracy: 0.8085 - val_loss: 0.4779\n",
      "Epoch 38/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7997 - loss: 0.4429 - val_accuracy: 0.8254 - val_loss: 0.4686\n",
      "Epoch 39/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7991 - loss: 0.4500 - val_accuracy: 0.8190 - val_loss: 0.4759\n",
      "Epoch 40/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8059 - loss: 0.4406 - val_accuracy: 0.8159 - val_loss: 0.4568\n",
      "Epoch 41/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8124 - loss: 0.4332 - val_accuracy: 0.8161 - val_loss: 0.4688\n",
      "Epoch 42/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7978 - loss: 0.4420 - val_accuracy: 0.7880 - val_loss: 0.5154\n",
      "Epoch 43/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7980 - loss: 0.4507 - val_accuracy: 0.7775 - val_loss: 0.5749\n",
      "Epoch 44/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8005 - loss: 0.4467 - val_accuracy: 0.8073 - val_loss: 0.4798\n",
      "Epoch 45/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8052 - loss: 0.4260 - val_accuracy: 0.7845 - val_loss: 0.5472\n",
      "Epoch 46/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8120 - loss: 0.4289 - val_accuracy: 0.7970 - val_loss: 0.4973\n",
      "Epoch 47/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8085 - loss: 0.4294 - val_accuracy: 0.8254 - val_loss: 0.4620\n",
      "Epoch 48/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8011 - loss: 0.4405 - val_accuracy: 0.8115 - val_loss: 0.4823\n",
      "Epoch 49/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4197 - val_accuracy: 0.7823 - val_loss: 0.5432\n",
      "Epoch 50/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8045 - loss: 0.4364 - val_accuracy: 0.8057 - val_loss: 0.4777\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape = (exercise_predictors_train.shape[1],)),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(256, activation = 'relu'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dense(len(np.unique(exercise_categories)), activation='softmax')\n",
    "])\n",
    " \n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(exercise_predictors_train, exercise_categories_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.6123 - loss: 1.2474 - val_accuracy: 0.7084 - val_loss: 0.7763\n",
      "Epoch 2/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7063 - loss: 0.6685 - val_accuracy: 0.7173 - val_loss: 0.6753\n",
      "Epoch 3/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7215 - loss: 0.6319 - val_accuracy: 0.7253 - val_loss: 0.6161\n",
      "Epoch 4/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7169 - loss: 0.6204 - val_accuracy: 0.7380 - val_loss: 0.5947\n",
      "Epoch 5/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7288 - loss: 0.5884 - val_accuracy: 0.7449 - val_loss: 0.6046\n",
      "Epoch 6/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7378 - loss: 0.5834 - val_accuracy: 0.7429 - val_loss: 0.6155\n",
      "Epoch 7/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7377 - loss: 0.5923 - val_accuracy: 0.7169 - val_loss: 0.6205\n",
      "Epoch 8/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7404 - loss: 0.5680 - val_accuracy: 0.7427 - val_loss: 0.5753\n",
      "Epoch 9/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7488 - loss: 0.5577 - val_accuracy: 0.7561 - val_loss: 0.5571\n",
      "Epoch 10/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7509 - loss: 0.5445 - val_accuracy: 0.7461 - val_loss: 0.5506\n",
      "Epoch 11/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7557 - loss: 0.5389 - val_accuracy: 0.7696 - val_loss: 0.5208\n",
      "Epoch 12/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7576 - loss: 0.5400 - val_accuracy: 0.7710 - val_loss: 0.5436\n",
      "Epoch 13/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7626 - loss: 0.5253 - val_accuracy: 0.7505 - val_loss: 0.5833\n",
      "Epoch 14/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7745 - loss: 0.5094 - val_accuracy: 0.8045 - val_loss: 0.5002\n",
      "Epoch 15/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7635 - loss: 0.5208 - val_accuracy: 0.7743 - val_loss: 0.5074\n",
      "Epoch 16/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7725 - loss: 0.5030 - val_accuracy: 0.7970 - val_loss: 0.5093\n",
      "Epoch 17/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7753 - loss: 0.5001 - val_accuracy: 0.7700 - val_loss: 0.5303\n",
      "Epoch 18/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7750 - loss: 0.5092 - val_accuracy: 0.7984 - val_loss: 0.4940\n",
      "Epoch 19/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7777 - loss: 0.4926 - val_accuracy: 0.7809 - val_loss: 0.5319\n",
      "Epoch 20/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7706 - loss: 0.5041 - val_accuracy: 0.7882 - val_loss: 0.5012\n",
      "Epoch 21/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7864 - loss: 0.4730 - val_accuracy: 0.7785 - val_loss: 0.4957\n",
      "Epoch 22/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7822 - loss: 0.4818 - val_accuracy: 0.7994 - val_loss: 0.4926\n",
      "Epoch 23/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7920 - loss: 0.4777 - val_accuracy: 0.8006 - val_loss: 0.4979\n",
      "Epoch 24/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7827 - loss: 0.4830 - val_accuracy: 0.7465 - val_loss: 0.5365\n",
      "Epoch 25/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7864 - loss: 0.4807 - val_accuracy: 0.7950 - val_loss: 0.4804\n",
      "Epoch 26/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7842 - loss: 0.4718 - val_accuracy: 0.7855 - val_loss: 0.5229\n",
      "Epoch 27/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7792 - loss: 0.4842 - val_accuracy: 0.7723 - val_loss: 0.4964\n",
      "Epoch 28/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7870 - loss: 0.4720 - val_accuracy: 0.7837 - val_loss: 0.4998\n",
      "Epoch 29/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7785 - loss: 0.4920 - val_accuracy: 0.7920 - val_loss: 0.4968\n",
      "Epoch 30/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7833 - loss: 0.4763 - val_accuracy: 0.7956 - val_loss: 0.4811\n",
      "Epoch 31/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7863 - loss: 0.4760 - val_accuracy: 0.8029 - val_loss: 0.4812\n",
      "Epoch 32/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7889 - loss: 0.4710 - val_accuracy: 0.7936 - val_loss: 0.5032\n",
      "Epoch 33/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7969 - loss: 0.4595 - val_accuracy: 0.8067 - val_loss: 0.4828\n",
      "Epoch 34/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7960 - loss: 0.4588 - val_accuracy: 0.7898 - val_loss: 0.4915\n",
      "Epoch 35/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7919 - loss: 0.4605 - val_accuracy: 0.8014 - val_loss: 0.4701\n",
      "Epoch 36/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7934 - loss: 0.4583 - val_accuracy: 0.8053 - val_loss: 0.4696\n",
      "Epoch 37/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7961 - loss: 0.4570 - val_accuracy: 0.8093 - val_loss: 0.4545\n",
      "Epoch 38/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7914 - loss: 0.4649 - val_accuracy: 0.8057 - val_loss: 0.4775\n",
      "Epoch 39/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7942 - loss: 0.4612 - val_accuracy: 0.8037 - val_loss: 0.4836\n",
      "Epoch 40/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8015 - loss: 0.4450 - val_accuracy: 0.7424 - val_loss: 0.6210\n",
      "Epoch 41/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7950 - loss: 0.4594 - val_accuracy: 0.8045 - val_loss: 0.4631\n",
      "Epoch 42/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7989 - loss: 0.4462 - val_accuracy: 0.8073 - val_loss: 0.4671\n",
      "Epoch 43/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8070 - loss: 0.4374 - val_accuracy: 0.8151 - val_loss: 0.4592\n",
      "Epoch 44/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7948 - loss: 0.4522 - val_accuracy: 0.8214 - val_loss: 0.4633\n",
      "Epoch 45/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7921 - loss: 0.4587 - val_accuracy: 0.7783 - val_loss: 0.5061\n",
      "Epoch 46/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8059 - loss: 0.4444 - val_accuracy: 0.7878 - val_loss: 0.4802\n",
      "Epoch 47/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7978 - loss: 0.4513 - val_accuracy: 0.8117 - val_loss: 0.4727\n",
      "Epoch 48/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8077 - loss: 0.4359 - val_accuracy: 0.8101 - val_loss: 0.4779\n",
      "Epoch 49/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8118 - loss: 0.4310 - val_accuracy: 0.8077 - val_loss: 0.4831\n",
      "Epoch 50/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8021 - loss: 0.4460 - val_accuracy: 0.8014 - val_loss: 0.4623\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape = (exercise_predictors_train.shape[1],)),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "     layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dense(len(np.unique(exercise_categories)), activation='softmax')\n",
    "])\n",
    " \n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(exercise_predictors_train, exercise_categories_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.5979 - loss: 3.0915 - val_accuracy: 0.7000 - val_loss: 0.7856\n",
      "Epoch 2/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6840 - loss: 0.8948 - val_accuracy: 0.6992 - val_loss: 0.8628\n",
      "Epoch 3/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7042 - loss: 0.7860 - val_accuracy: 0.6742 - val_loss: 1.0858\n",
      "Epoch 4/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7074 - loss: 0.7749 - val_accuracy: 0.7128 - val_loss: 0.6830\n",
      "Epoch 5/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7066 - loss: 0.7240 - val_accuracy: 0.7271 - val_loss: 0.7104\n",
      "Epoch 6/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7083 - loss: 0.7325 - val_accuracy: 0.7280 - val_loss: 0.6917\n",
      "Epoch 7/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7256 - loss: 0.6790 - val_accuracy: 0.7306 - val_loss: 0.7279\n",
      "Epoch 8/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7245 - loss: 0.6684 - val_accuracy: 0.7191 - val_loss: 0.6907\n",
      "Epoch 9/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7218 - loss: 0.6631 - val_accuracy: 0.7483 - val_loss: 0.6190\n",
      "Epoch 10/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7304 - loss: 0.6232 - val_accuracy: 0.7424 - val_loss: 0.6387\n",
      "Epoch 11/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7347 - loss: 0.6142 - val_accuracy: 0.7533 - val_loss: 0.6163\n",
      "Epoch 12/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7309 - loss: 0.6323 - val_accuracy: 0.7388 - val_loss: 0.6155\n",
      "Epoch 13/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7354 - loss: 0.6034 - val_accuracy: 0.7396 - val_loss: 0.6429\n",
      "Epoch 14/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7359 - loss: 0.5974 - val_accuracy: 0.7193 - val_loss: 0.6657\n",
      "Epoch 15/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7421 - loss: 0.5841 - val_accuracy: 0.7479 - val_loss: 0.6054\n",
      "Epoch 16/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7366 - loss: 0.5863 - val_accuracy: 0.7626 - val_loss: 0.6031\n",
      "Epoch 17/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7361 - loss: 0.5924 - val_accuracy: 0.7563 - val_loss: 0.5950\n",
      "Epoch 18/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7412 - loss: 0.5807 - val_accuracy: 0.7433 - val_loss: 0.6148\n",
      "Epoch 19/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7442 - loss: 0.5684 - val_accuracy: 0.7314 - val_loss: 0.6114\n",
      "Epoch 20/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7431 - loss: 0.5701 - val_accuracy: 0.7410 - val_loss: 0.5915\n",
      "Epoch 21/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7503 - loss: 0.5515 - val_accuracy: 0.7282 - val_loss: 0.6441\n",
      "Epoch 22/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7533 - loss: 0.5598 - val_accuracy: 0.7523 - val_loss: 0.5853\n",
      "Epoch 23/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7489 - loss: 0.5470 - val_accuracy: 0.7559 - val_loss: 0.5592\n",
      "Epoch 24/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7637 - loss: 0.5367 - val_accuracy: 0.7716 - val_loss: 0.5537\n",
      "Epoch 25/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7521 - loss: 0.5529 - val_accuracy: 0.7855 - val_loss: 0.5566\n",
      "Epoch 26/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7583 - loss: 0.5405 - val_accuracy: 0.7580 - val_loss: 0.5518\n",
      "Epoch 27/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7699 - loss: 0.5283 - val_accuracy: 0.7727 - val_loss: 0.5563\n",
      "Epoch 28/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7662 - loss: 0.5210 - val_accuracy: 0.7481 - val_loss: 0.5698\n",
      "Epoch 29/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7689 - loss: 0.5239 - val_accuracy: 0.7489 - val_loss: 0.5845\n",
      "Epoch 30/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7698 - loss: 0.5219 - val_accuracy: 0.7749 - val_loss: 0.5516\n",
      "Epoch 31/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7636 - loss: 0.5310 - val_accuracy: 0.7263 - val_loss: 0.6725\n",
      "Epoch 32/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7579 - loss: 0.5308 - val_accuracy: 0.7531 - val_loss: 0.5781\n",
      "Epoch 33/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7670 - loss: 0.5163 - val_accuracy: 0.7592 - val_loss: 0.5715\n",
      "Epoch 34/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7690 - loss: 0.5123 - val_accuracy: 0.7767 - val_loss: 0.5563\n",
      "Epoch 35/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7775 - loss: 0.5029 - val_accuracy: 0.7549 - val_loss: 0.5646\n",
      "Epoch 36/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7679 - loss: 0.5147 - val_accuracy: 0.7751 - val_loss: 0.5422\n",
      "Epoch 37/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7745 - loss: 0.5028 - val_accuracy: 0.7491 - val_loss: 0.5896\n",
      "Epoch 38/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7778 - loss: 0.4970 - val_accuracy: 0.7853 - val_loss: 0.5324\n",
      "Epoch 39/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7789 - loss: 0.5021 - val_accuracy: 0.7789 - val_loss: 0.5440\n",
      "Epoch 40/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7784 - loss: 0.5034 - val_accuracy: 0.7932 - val_loss: 0.5204\n",
      "Epoch 41/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7800 - loss: 0.4959 - val_accuracy: 0.8031 - val_loss: 0.5306\n",
      "Epoch 42/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7792 - loss: 0.4924 - val_accuracy: 0.7817 - val_loss: 0.5420\n",
      "Epoch 43/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7801 - loss: 0.5036 - val_accuracy: 0.7892 - val_loss: 0.5136\n",
      "Epoch 44/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7776 - loss: 0.4911 - val_accuracy: 0.7652 - val_loss: 0.5586\n",
      "Epoch 45/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7822 - loss: 0.4840 - val_accuracy: 0.7731 - val_loss: 0.5577\n",
      "Epoch 46/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7807 - loss: 0.4910 - val_accuracy: 0.7471 - val_loss: 0.6046\n",
      "Epoch 47/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7786 - loss: 0.4953 - val_accuracy: 0.7992 - val_loss: 0.5406\n",
      "Epoch 48/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7858 - loss: 0.4927 - val_accuracy: 0.7783 - val_loss: 0.5416\n",
      "Epoch 49/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7765 - loss: 0.4913 - val_accuracy: 0.8025 - val_loss: 0.5141\n",
      "Epoch 50/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7879 - loss: 0.4864 - val_accuracy: 0.7843 - val_loss: 0.5288\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape = (exercise_predictors_train.shape[1],)),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(len(np.unique(exercise_categories)), activation='softmax')\n",
    "])\n",
    " \n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(exercise_predictors_train, exercise_categories_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linux-deep-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
